{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, string, requests, pprint, nltk, operator, numpy as np, math, tqdm\n",
    "from time import gmtime, strftime\n",
    "from functools import wraps\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print ('func:%r args:[%r, %r] took: %2.4f sec' % \\\n",
    "          (f.__name__, args, kw, te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_judgment(judgment):\n",
    "    data_to_query = (\",\").join(judgment)\n",
    "    r = requests.post(data=data_to_query.encode(\"utf-8\"), url=\"http://localhost:9200\")\n",
    "    response_text = r.text\n",
    "    splited_response = response_text.splitlines()\n",
    "    splited_response = [\" \".join(x.replace(\"\\t\", \" \").replace(\"none\", \"\")[1:].split(\":\")[:2][:1]).replace(\" \", \":\")\n",
    "                        for x in splited_response if \":\" in x]\n",
    "    return splited_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [00:02<00:20,  2.60s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [00:04<00:14,  2.00s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [00:05<00:10,  1.78s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [00:07<00:09,  1.86s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [00:11<00:08,  2.25s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [00:25<00:12,  4.24s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [00:26<00:07,  3.82s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [00:28<00:03,  3.51s/it]\u001b[A\n",
      "100%|██████████| 9/9 [00:31<00:00,  3.46s/it]\u001b[A\n",
      "  8%|▊         | 1/12 [00:31<05:42, 31.11s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:50,  1.95it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:02<01:43,  1.06s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:05<03:13,  1.99s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:10<04:12,  2.63s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:11<03:30,  2.21s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:14<03:41,  2.36s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:14<03:15,  2.10s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:17<03:17,  2.15s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:20<03:27,  2.28s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:27<04:04,  2.72s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:27<03:44,  2.52s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:28<03:27,  2.36s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:28<03:13,  2.23s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:29<02:58,  2.07s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:29<02:45,  1.94s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:29<02:33,  1.83s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:29<02:23,  1.73s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:29<02:14,  1.64s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:31<02:13,  1.65s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:39<02:36,  1.96s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:42<02:39,  2.02s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:42<02:32,  1.95s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:47<02:39,  2.07s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:50<02:39,  2.09s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:51<02:34,  2.06s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:53<02:31,  2.05s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:55<02:29,  2.04s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:55<02:23,  1.99s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:57<02:20,  1.98s/it]\u001b[A\n",
      " 30%|███       | 30/100 [00:59<02:19,  1.99s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:01<02:11,  1.94s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:04<02:10,  1.95s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:06<02:09,  1.97s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:07<02:05,  1.94s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:11<02:06,  1.98s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:11<02:02,  1.94s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:13<01:59,  1.93s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:14<01:56,  1.91s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:17<01:55,  1.93s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:18<01:53,  1.92s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:19<01:50,  1.90s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:20<01:46,  1.88s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:21<01:43,  1.86s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:24<01:43,  1.88s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:28<01:44,  1.93s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:42<01:56,  2.19s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:45<01:54,  2.20s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:49<01:54,  2.24s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [02:01<02:01,  2.42s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [02:02<01:57,  2.39s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [02:03<01:54,  2.38s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [02:04<01:50,  2.35s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [02:04<01:46,  2.31s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [02:17<01:52,  2.51s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [02:21<01:51,  2.53s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [02:25<01:49,  2.56s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [02:33<01:51,  2.65s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [02:36<01:49,  2.66s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:40<01:47,  2.68s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:50<01:48,  2.79s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:50<01:44,  2.76s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:51<01:40,  2.72s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:51<01:36,  2.69s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:53<01:33,  2.67s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:54<01:30,  2.65s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:58<01:27,  2.66s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:58<01:20,  2.58s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [03:02<01:18,  2.61s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [03:07<01:16,  2.64s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [03:08<01:13,  2.61s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [03:11<01:10,  2.62s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [03:15<01:08,  2.64s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [03:17<01:05,  2.63s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [03:18<01:02,  2.62s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [03:19<00:59,  2.60s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [03:23<00:57,  2.61s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [03:23<00:50,  2.54s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [03:23<00:44,  2.48s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [03:23<00:38,  2.43s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [03:24<00:36,  2.40s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [03:26<00:33,  2.40s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [03:28<00:31,  2.40s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:37<00:29,  2.48s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:47<00:28,  2.55s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:48<00:25,  2.54s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:52<00:23,  2.56s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:53<00:20,  2.54s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:58<00:17,  2.56s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:59<00:15,  2.55s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [04:08<00:13,  2.62s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [04:36<00:11,  2.88s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [04:38<00:08,  2.87s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [04:41<00:05,  2.88s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [04:43<00:02,  2.86s/it]\u001b[A\n",
      "100%|██████████| 100/100 [04:44<00:00,  2.84s/it]\u001b[A\n",
      " 17%|█▋        | 2/12 [05:15<26:17, 157.77s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:57,  2.40s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:25,  2.10s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:05<02:44,  1.70s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:07<03:06,  1.94s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:11<03:46,  2.38s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:15<04:07,  2.63s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:18<04:11,  2.71s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:22<04:23,  2.86s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:23<03:58,  2.63s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:25<03:47,  2.53s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:28<03:47,  2.56s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:29<03:38,  2.49s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:31<03:29,  2.41s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:37<03:48,  2.65s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:39<03:43,  2.63s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:41<03:38,  2.60s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:44<03:37,  2.62s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:48<03:40,  2.69s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:49<03:30,  2.60s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:50<03:20,  2.50s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:51<03:14,  2.46s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open (file_path) as file:\n",
    "        json_content = json.load(file)\n",
    "        item_count = 0\n",
    "        for item in tqdm.tqdm(json_content):\n",
    "            judgment = []\n",
    "            item_count += 1\n",
    "            text_content = re.sub(\"<.*?>\", \"\", item[\"textContent\"])\n",
    "            text_content = text_content.replace('-\\n', '')\n",
    "            word_content = text_content.split()\n",
    "            topicSpecificPunctuation = '„”–§…«»'\n",
    "            translator = str.maketrans('', '', string.punctuation+topicSpecificPunctuation)\n",
    "            \n",
    "            for word in word_content:\n",
    "                word = word.translate(translator).lower()\n",
    "                if len(word)>0:\n",
    "                    judgment.append(word)\n",
    "            unigrams = process_judgment(judgment)\n",
    "                \n",
    "            with open(file_path + \"_results.txt\", 'w') as out_file:\n",
    "                for unigram in unigrams:\n",
    "                    out_file.write(unigram + \"\\n\")\n",
    "     \n",
    "def read_all_judgments_from_2018():\n",
    "    with open(\"../data_filtered/raport.txt\", \"a\") as raport_file:\n",
    "        for filename in tqdm.tqdm(os.listdir(\"../data_filtered/\")):\n",
    "            if not filename + \"_results.txt\" in os.listdir(\"../data_filtered/\"):\n",
    "                raport_file.write(str(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) + \" \")\n",
    "                raport_file.write(\"Writing to file \" + filename + \"\\n\")\n",
    "                raport_file.flush()\n",
    "                read_file(\"../data_filtered/\" + filename)\n",
    "                raport_file.write(str(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) + \" \")\n",
    "                raport_file.write(\"Writing to file \" + filename + \"FINISHED \\n\")\n",
    "                raport_file.flush()\n",
    "        \n",
    "read_all_judgments_from_2018()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(file_path):\n",
    "    with open(file_path) as file:\n",
    "        content = file.read().split(\"\\n\")\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_response = processed_unigrams\n",
    "splited_response = [item for sublist in splited_response for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = nltk.bigrams(splited_response)\n",
    "unigrams_frequency = nltk.FreqDist(splited_response)\n",
    "bigrams_frequency = nltk.FreqDist(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_unigrams = sorted(unigrams_frequency.items(), key=operator.itemgetter(1), reverse=True)\n",
    "pprint.pprint(sorted_unigrams[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_bigrams = sorted(bigrams_frequency.items(), key=operator.itemgetter(1), reverse=True)\n",
    "pprint.pprint(sorted_bigrams[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOTAL_COUNT = len(splited_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shannon_entrophy(word_occurences, total_words):\n",
    "    sum = 0\n",
    "    for x in np.nditer(word_occurences):\n",
    "        if x!= 0:\n",
    "            sum += (x/total_words) * math.log(x/total_words)\n",
    "    return sum\n",
    "\n",
    "def H(word_occurences):\n",
    "    return shannon_entrophy(word_occurences, TOTAL_COUNT)\n",
    "\n",
    "def calculate_contingency_table(bigram, bigram_count, total_words):\n",
    "    first, second = bigram[0], bigram[1]\n",
    "    first_occurence, second_occurence = unigrams_frequency[first], unigrams_frequency[second]\n",
    "    '''\n",
    "    |------  |---------| \n",
    "    | A,B    |B,notA   |\n",
    "    |------  |---------|\n",
    "    | A,notB |notA,notB|\n",
    "    |------|---------|\n",
    "    '''\n",
    "    return np.array([\n",
    "            [bigram_count, first_occurence-bigram_count],\n",
    "            [second_occurence-bigram_count, total_words-first_occurence-second_occurence-bigram_count]])\n",
    "\n",
    "def log_likeliheood_ratio(bigram_key):\n",
    "    k = calculate_contingency_table(bigram_key, bigrams_frequency[bigram_key], TOTAL_COUNT)\n",
    "    return 2 * np.sum(k) * (H(k) - H(k.sum(axis=0)) -H(k.sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ratios = [(key, log_likeliheood_ratio(key), value) for key, value in bigrams_frequency.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_log_ratios = sorted(log_ratios, key=operator.itemgetter(1), reverse=True)\n",
    "sorted_by_log_ratios[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_by_tags = [log_ratio for log_ratio in log_ratios \n",
    "                    if \"subst\" in log_ratio[0][0] and\n",
    "                    (\"subst\" in log_ratio[0][1] or \"adj\" in log_ratio[0][1])]\n",
    "filtered_by_tags_sorted = sorted(filtered_by_tags, key=operator.itemgetter(1), reverse=True)\n",
    "filtered_by_tags_sorted[:30]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
