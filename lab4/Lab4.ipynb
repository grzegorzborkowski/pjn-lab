{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pprint\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judgments-3163.json\n",
      "9\n",
      "judgments-3168.json\n",
      "100\n",
      "judgments-3164.json\n",
      "100\n",
      "judgments-3171.json\n",
      "100\n",
      "judgments-3165.json\n",
      "100\n",
      "judgments-3167.json\n",
      "100\n",
      "judgments-3169.json\n",
      "100\n",
      "judgments-3173.json\n",
      "81\n",
      "judgments-3172.json\n",
      "100\n",
      "judgments-3166.json\n",
      "100\n",
      "judgments-3170.json\n",
      "100\n",
      "2530124\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open (file_path) as file:\n",
    "        json_content = json.load(file)\n",
    "        item_count = 0\n",
    "        for item in json_content:\n",
    "            item_count += 1\n",
    "            text_content = re.sub(\"<.*?>\", \"\", item[\"textContent\"])\n",
    "            text_content = text_content.replace('-\\n', '')\n",
    "            word_content = text_content.split()\n",
    "            topicSpecificPunctuation = '„”–§…«»'\n",
    "            translator = str.maketrans('', '', string.punctuation+topicSpecificPunctuation)\n",
    "            \n",
    "            for word in word_content:\n",
    "                word = word.translate(translator).lower()\n",
    "                if len(word)>0:\n",
    "                    all_words.append(word)\n",
    "                \n",
    "        print(item_count)\n",
    "        \n",
    "def read_all_judgments_from_2018():\n",
    "    for filename in os.listdir(\"data_filtered/\"):\n",
    "        print(filename)\n",
    "        read_file(\"data_filtered/\" + filename)\n",
    "        \n",
    "read_all_judgments_from_2018()\n",
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "CHANGE_TO_BASIC_FORM = False\n",
    "sorted_rank = {}\n",
    "TOTAL_COUNT = len(all_words)\n",
    "\n",
    "def generate_rank():        \n",
    "    words_rank = {}\n",
    "    for word in all_words:\n",
    "        current = words_rank.get(word)\n",
    "        \n",
    "        if current is None:\n",
    "            words_rank[word] = 1\n",
    "        else:\n",
    "            words_rank[word] = current + 1\n",
    "    \n",
    "    return words_rank\n",
    "\n",
    "sorted_rank = generate_rank()\n",
    "print (type(sorted_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_filter(word):\n",
    "    if re.match(\"^[a-ząćęłńóśźż]+$\", word):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def filter_list(list_of_words):\n",
    "    return [word for word in list_of_words if custom_filter(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uzasadnienie', 'powód', 'sp', 'z', 'oo', 'sp', 'k', 'z', 'siedzibą', 'w']\n"
     ]
    }
   ],
   "source": [
    "words = filter_list(all_words)\n",
    "pprint.pprint(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uzasadnienie 1092\n",
      "powód 3746\n",
      "sp 1461\n",
      "z 69427\n",
      "oo 1468\n",
      "k 16810\n",
      "siedzibą 1189\n",
      "w 117267\n",
      "p 5069\n",
      "wniósł 1181\n"
     ]
    }
   ],
   "source": [
    "counter, limit = 0, 10\n",
    "for k, v in sorted_rank.items():\n",
    "    if counter < limit:\n",
    "        print (k, v)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigrams = nltk.bigrams(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uzasadnienie', 'powód') 73\n",
      "('powód', 'sp') 5\n",
      "('sp', 'z') 1417\n",
      "('z', 'oo') 1463\n",
      "('oo', 'sp') 14\n",
      "('sp', 'k') 14\n",
      "('k', 'z') 426\n",
      "('z', 'siedzibą') 1169\n",
      "('siedzibą', 'w') 1052\n",
      "('w', 'p') 694\n"
     ]
    }
   ],
   "source": [
    "bigrams_frequency = nltk.FreqDist(bigrams)\n",
    "counter, limit = 0, 10\n",
    "\n",
    "\n",
    "for k,v in bigrams_frequency.items():\n",
    "    if counter < limit:\n",
    "        print (k,v)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pointwise_mutual_information(bigram, bigram_count):\n",
    "    probability_of_bigram = bigram_count / TOTAL_COUNT\n",
    "    first, second = bigram[0], bigram[1]\n",
    "    probability_of_first, probability_of_second = sorted_rank[first]/TOTAL_COUNT, sorted_rank[second]/TOTAL_COUNT\n",
    "    return math.log(probability_of_bigram/(probability_of_first*probability_of_second))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pointwise mutual information\n",
    "bigram_result = {}\n",
    "for bigram, bigram_count in bigrams_frequency.items():\n",
    "    bigram_result[bigram] = (pointwise_mutual_information(bigram, bigram_count), bigram_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uzasadnienie', 'powód') (3.8100282731998756, 73)\n",
      "('powód', 'sp') (0.8378964890397356, 5)\n",
      "('sp', 'z') (3.565168579474035, 1417)\n",
      "('z', 'oo') (3.5923359433797177, 1463)\n",
      "('oo', 'sp') (2.8043035800504668, 14)\n",
      "('sp', 'k') (0.3662305628222664, 14)\n",
      "('k', 'z') (-0.07954212859923658, 426)\n",
      "('z', 'siedzibą') (3.5787838163153407, 1169)\n",
      "('siedzibą', 'w') (2.9491507028296353, 1052)\n",
      "('w', 'p') (1.083143328257217, 694)\n"
     ]
    }
   ],
   "source": [
    "counter, limit = 0, 10\n",
    "\n",
    "for k,v in bigram_result.items():\n",
    "    if counter < limit:\n",
    "        print (k,v)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('prosze', 'stawic') (14.74377887136037, 1)\n",
      "('obowiazuje', 'cie') (14.74377887136037, 1)\n",
      "('cie', 'miesieczby') (14.74377887136037, 1)\n",
      "('porysowała', 'barierkę') (14.74377887136037, 1)\n",
      "('podziemny', 'zamykający') (14.74377887136037, 1)\n",
      "('kompleksów', 'skraplania') (14.74377887136037, 1)\n",
      "('ewidencyjno', 'sprawozdawczym') (14.74377887136037, 1)\n",
      "('wielichowska', 'opalska') (14.74377887136037, 1)\n",
      "('nowakowski', 'andżelika') (14.74377887136037, 1)\n",
      "('andżelika', 'pruk') (14.74377887136037, 1)\n",
      "('odsuniętej', 'szybie') (14.74377887136037, 1)\n",
      "('wgnieciona', 'obręcz') (14.74377887136037, 1)\n",
      "('krata', 'wlotu') (14.74377887136037, 1)\n",
      "('odepchnięty', 'obrócił') (14.74377887136037, 1)\n",
      "('nawierzchnią', 'gruntowotrawiastą') (14.74377887136037, 1)\n",
      "('sadowski', 'czasowoprzestrzenna') (14.74377887136037, 1)\n",
      "('dodatnią', 'prognozą') (14.74377887136037, 1)\n",
      "('osobnikiem', 'zdemoralizowanym') (14.74377887136037, 1)\n",
      "('beaty', 'tonasko') (14.74377887136037, 1)\n",
      "('artykułując', 'przezwiska') (14.74377887136037, 1)\n",
      "('literacką', 'objętość') (14.74377887136037, 1)\n",
      "('nieobliczalny', 'nieprzewidywalny') (14.74377887136037, 1)\n",
      "('snopki', 'koszeniem') (14.74377887136037, 1)\n",
      "('nieprawidłowościom', 'zapobieganiu') (14.74377887136037, 1)\n",
      "('zapobieganiu', 'ubytkom') (14.74377887136037, 1)\n",
      "('sprzedażowej', 'wnikało') (14.74377887136037, 1)\n",
      "('statywu', 'lunety') (14.74377887136037, 1)\n",
      "('optycznym', 'generowanym') (14.74377887136037, 1)\n",
      "('oświetlał', 'laserową') (14.74377887136037, 1)\n",
      "('laserową', 'wiązką') (14.74377887136037, 1)\n"
     ]
    }
   ],
   "source": [
    "MINIMUM_BIGRAM_OCCURENCE = -1\n",
    "\n",
    "sd = sorted(bigram_result.items(), key=lambda key_value: key_value[1][0], reverse=True)\n",
    "counter, limit = 0, 30\n",
    "for k,v in sd:\n",
    "    if counter < limit and v[1] > MINIMUM_BIGRAM_OCCURENCE:\n",
    "        print (k,v)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shannon_entrophy(word_occurences, total_words):\n",
    "    sum = 0\n",
    "    for x in np.nditer(word_occurences):\n",
    "        if x!= 0:\n",
    "            sum += (x/total_words) * math.log(x/total_words)\n",
    "    return sum\n",
    "\n",
    "def H(word_occurences):\n",
    "    return shannon_entrophy(word_occurences, TOTAL_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_contingency_table(bigram, bigram_count, total_words):\n",
    "    first, second = bigram[0], bigram[1]\n",
    "    first_occurence, second_occurence = sorted_rank[first], sorted_rank[second]\n",
    "    '''\n",
    "    |------  |---------| \n",
    "    | A,B    |B,notA   |\n",
    "    |------  |---------|\n",
    "    | A,notB |notA,notB|\n",
    "    |------|---------|\n",
    "    '''\n",
    "    return np.array([\n",
    "            [bigram_count, first_occurence-bigram_count],\n",
    "            [second_occurence-bigram_count, total_words-first_occurence-second_occurence]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likeliheood_ratio(bigram_key):\n",
    "    k = calculate_contingency_table(bigram_key, bigram_result[bigram_key][1], TOTAL_COUNT)\n",
    "\n",
    "    return 2 * np.sum(k) * (H(k) - H(k.sum(axis=0)) -H(k.sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9.305699562437173, 120)\n"
     ]
    }
   ],
   "source": [
    "print (bigram_result[('stawek', 'dziennych')])\n",
    "counter, limit = 0, 10\n",
    "\n",
    "log_ratios = [(key, log_likeliheood_ratio(key), value[1]) for key, value in bigram_result.items()]\n",
    "\n",
    "# print (log_likeliheood_ratio(('stawek', 'dziennych')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('z', 'dnia'), 86952.744987227095, (3.1599235647023516, 11852)),\n",
      " (('na', 'podstawie'), 46081.661634982847, (4.02483424835121, 4694)),\n",
      " (('ubezpieczeń', 'społecznych'),\n",
      "  44522.179009044834,\n",
      "  (6.784678163048855, 2620)),\n",
      " (('w', 'dniu'), 39886.546419177925, (3.005591800027203, 5205)),\n",
      " (('art', 'kpc'), 35546.057674896678, (4.808019871681763, 3207)),\n",
      " (('sygn', 'akt'), 34392.293122109972, (6.085967109668274, 2435)),\n",
      " (('art', 'ust'), 32659.421496778694, (4.626651795043272, 3142)),\n",
      " (('sąd', 'okręgowy'), 30570.779660573575, (5.187985965521512, 2452)),\n",
      " (('w', 'sprawie'), 29855.654486413114, (2.704789408281566, 4647)),\n",
      " (('zgodnie', 'z'), 28773.168524345179, (3.4943666905382997, 3374)),\n",
      " (('art', 'kc'), 27015.85769147292, (4.852914016146875, 2404)),\n",
      " (('sąd', 'rejonowy'), 26907.068155841178, (5.182833943022735, 2170)),\n",
      " (('na', 'rzecz'), 26315.727073114645, (3.9176388942580305, 2851)),\n",
      " (('w', 'tym'), 23268.145128867029, (2.4019279949601753, 4197)),\n",
      " (('sądu', 'najwyższego'), 22077.430191232157, (5.856548836738101, 1594)),\n",
      " (('organ', 'rentowy'), 21968.763047897857, (7.481459082795513, 1206)),\n",
      " (('o', 'pracę'), 21533.928706763898, (4.10566936449734, 2354)),\n",
      " (('z', 'art'), 20200.91251703247, (2.1789935847003927, 4179)),\n",
      " (('z', 'tytułu'), 19752.79118955358, (3.3336579233304637, 2523)),\n",
      " (('od', 'dnia'), 18868.079269473757, (3.1523415155033003, 2818)),\n",
      " (('art', 'kk'), 18465.235132131154, (4.755023299966322, 1713)),\n",
      " (('zw', 'z'), 18426.957708990198, (3.5754179129337555, 2045)),\n",
      " (('stycznia', 'r'), 17798.542822363164, (4.1177910433056395, 1982)),\n",
      " (('związku', 'z'), 17417.224935589846, (3.407309494162588, 2146)),\n",
      " (('do', 'pracy'), 17378.839670242745, (2.7344105890999435, 2955)),\n",
      " (('w', 'związku'), 16835.796505583694, (2.9480781222089374, 2290)),\n",
      " (('w', 'zw'), 16766.762084275826, (3.0658037318103597, 2075)),\n",
      " (('podstawie', 'art'), 16753.157556857346, (4.04804990955542, 1931)),\n",
      " (('ocenie', 'sądu'), 16538.596974685886, (5.465447701858084, 1374)),\n",
      " (('kwotę', 'zł'), 16309.035588944718, (5.017287722020233, 1494))]\n"
     ]
    }
   ],
   "source": [
    "sd = sorted(log_ratios, key=lambda key_value: key_value[1], reverse=True)\n",
    "pprint.pprint(sd[:30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
