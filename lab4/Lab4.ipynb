{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pprint\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judgments-3163.json\n",
      "9\n",
      "judgments-3168.json\n",
      "100\n",
      "judgments-3164.json\n",
      "100\n",
      "judgments-3171.json\n",
      "100\n",
      "judgments-3165.json\n",
      "100\n",
      "judgments-3167.json\n",
      "100\n",
      "judgments-3169.json\n",
      "100\n",
      "judgments-3173.json\n",
      "81\n",
      "judgments-3172.json\n",
      "100\n",
      "judgments-3166.json\n",
      "100\n",
      "judgments-3170.json\n",
      "100\n",
      "2530124\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open (file_path) as file:\n",
    "        json_content = json.load(file)\n",
    "        item_count = 0\n",
    "        for item in json_content:\n",
    "            item_count += 1\n",
    "            text_content = re.sub(\"<.*?>\", \"\", item[\"textContent\"])\n",
    "            text_content = text_content.replace('-\\n', '')\n",
    "            word_content = text_content.split()\n",
    "            topicSpecificPunctuation = '„”–§…«»'\n",
    "            translator = str.maketrans('', '', string.punctuation+topicSpecificPunctuation)\n",
    "            \n",
    "            for word in word_content:\n",
    "                word = word.translate(translator).lower()\n",
    "                if len(word)>0:\n",
    "                    all_words.append(word)\n",
    "                \n",
    "        print(item_count)\n",
    "        \n",
    "def read_all_judgments_from_2018():\n",
    "    for filename in os.listdir(\"data_filtered/\"):\n",
    "        print(filename)\n",
    "        read_file(\"data_filtered/\" + filename)\n",
    "        \n",
    "read_all_judgments_from_2018()\n",
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "CHANGE_TO_BASIC_FORM = False\n",
    "sorted_rank = {}\n",
    "TOTAL_COUNT = len(all_words)\n",
    "\n",
    "def generate_rank():        \n",
    "    words_rank = {}\n",
    "    for word in all_words:\n",
    "        current = words_rank.get(word)\n",
    "        \n",
    "        if current is None:\n",
    "            words_rank[word] = 1\n",
    "        else:\n",
    "            words_rank[word] = current + 1\n",
    "    \n",
    "    return words_rank\n",
    "\n",
    "sorted_rank = generate_rank()\n",
    "print (type(sorted_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_filter(word):\n",
    "    if re.match(\"^[a-ząćęłńóśźż]+$\", word):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def filter_list(list_of_words):\n",
    "    return [word for word in list_of_words if custom_filter(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uzasadnienie', 'powód', 'sp', 'z', 'oo', 'sp', 'k', 'z', 'siedzibą', 'w']\n"
     ]
    }
   ],
   "source": [
    "words = filter_list(all_words)\n",
    "pprint.pprint(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uzasadnienie 1092\n",
      "powód 3746\n",
      "sp 1461\n",
      "z 69427\n",
      "oo 1468\n",
      "k 16810\n",
      "siedzibą 1189\n",
      "w 117267\n",
      "p 5069\n",
      "wniósł 1181\n"
     ]
    }
   ],
   "source": [
    "counter, limit = 0, 10\n",
    "for k, v in sorted_rank.items():\n",
    "    if counter < limit:\n",
    "        print (k, v)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigrams = nltk.bigrams(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uzasadnienie', 'powód') 73\n",
      "('powód', 'sp') 5\n",
      "('sp', 'z') 1417\n",
      "('z', 'oo') 1463\n",
      "('oo', 'sp') 14\n",
      "('sp', 'k') 14\n",
      "('k', 'z') 426\n",
      "('z', 'siedzibą') 1169\n",
      "('siedzibą', 'w') 1052\n",
      "('w', 'p') 694\n"
     ]
    }
   ],
   "source": [
    "bigrams_frequency = nltk.FreqDist(bigrams)\n",
    "counter, limit = 0, 10\n",
    "\n",
    "\n",
    "for k,v in bigrams_frequency.items():\n",
    "    if counter < limit:\n",
    "        print (k,v)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pointwise_mutual_information(bigram, bigram_count):\n",
    "    probability_of_bigram = bigram_count / TOTAL_COUNT\n",
    "    first, second = bigram[0], bigram[1]\n",
    "    probability_of_first, probability_of_second = sorted_rank[first]/TOTAL_COUNT, sorted_rank[second]/TOTAL_COUNT\n",
    "    return math.log(probability_of_bigram/(probability_of_first*probability_of_second))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pointwise mutual information\n",
    "bigram_result = {}\n",
    "for bigram, bigram_count in bigrams_frequency.items():\n",
    "    bigram_result[bigram] = (pointwise_mutual_information(bigram, bigram_count), bigram_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('uzasadnienie', 'powód') (3.8100282731998756, 73)\n",
      "('powód', 'sp') (0.8378964890397356, 5)\n",
      "('sp', 'z') (3.565168579474035, 1417)\n",
      "('z', 'oo') (3.5923359433797177, 1463)\n",
      "('oo', 'sp') (2.8043035800504668, 14)\n",
      "('sp', 'k') (0.3662305628222664, 14)\n",
      "('k', 'z') (-0.07954212859923658, 426)\n",
      "('z', 'siedzibą') (3.5787838163153407, 1169)\n",
      "('siedzibą', 'w') (2.9491507028296353, 1052)\n",
      "('w', 'p') (1.083143328257217, 694)\n"
     ]
    }
   ],
   "source": [
    "counter, limit = 0, 10\n",
    "\n",
    "for k,v in bigram_result.items():\n",
    "    if counter < limit:\n",
    "        print (k,v)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('samorządowej', 'jednostce') (9.659856309547225, 101)\n",
      "('trybunału', 'konstytucyjnego') (9.655208351930142, 114)\n",
      "('zdrowotnej', 'finansowanych') (9.584079242226641, 107)\n",
      "('księgę', 'wieczystą') (9.58262761293319, 126)\n",
      "('sfery', 'budżetowej') (9.476135511997146, 144)\n",
      "('doznaną', 'krzywdę') (9.47101457923695, 109)\n",
      "('uzasadnieniem', 'doręczyć') (9.427498804438159, 104)\n",
      "('stawek', 'dziennych') (9.305699562437173, 120)\n",
      "('grach', 'hazardowych') (9.292592434072608, 174)\n",
      "('gospodarstwa', 'rolnego') (9.260375133292637, 152)\n",
      "('jednostce', 'sfery') (9.187870519097498, 105)\n",
      "('obszaru', 'ograniczonego') (9.164520854771906, 120)\n",
      "('gospodarstwie', 'rolnym') (9.092264825249924, 180)\n",
      "('ograniczonego', 'użytkowania') (9.046099639743833, 189)\n",
      "('służby', 'wojskowej') (9.030311306116026, 112)\n",
      "('godzinach', 'nadliczbowych') (8.989466834746212, 124)\n",
      "('st', 'sekr') (8.9886036047791, 134)\n",
      "('tekst', 'jednolity') (8.983946361279594, 166)\n",
      "('utraciła', 'zdolność') (8.923984075626493, 103)\n",
      "('doświadczenia', 'życiowego') (8.902279146146967, 298)\n",
      "('kapitału', 'początkowego') (8.84838390163782, 247)\n",
      "('materiałem', 'dowodowym') (8.803959793322218, 142)\n",
      "('komisji', 'lekarskiej') (8.781776356982704, 124)\n",
      "('pracownikowi', 'zatrudnionemu') (8.777028995909587, 102)\n",
      "('lekarza', 'orzecznika') (8.769849991794622, 128)\n",
      "('punktu', 'widzenia') (8.763717678737224, 254)\n",
      "('emerytalnemu', 'rentowym') (8.759867530505833, 101)\n",
      "('materiale', 'dowodowym') (8.738342617267, 129)\n",
      "('sprawności', 'organizmu') (8.732362029964982, 131)\n",
      "('granicami', 'kraju') (8.667035216005047, 143)\n"
     ]
    }
   ],
   "source": [
    "MINIMUM_BIGRAM_OCCURENCE = 100\n",
    "\n",
    "sd = sorted(bigram_result.items(), key=lambda key_value: key_value[1][0], reverse=True)\n",
    "counter, limit = 0, 30\n",
    "for k,v in sd:\n",
    "    if counter < limit and v[1] > MINIMUM_BIGRAM_OCCURENCE:\n",
    "        print (k,v)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shannon_entrophy(word_occurences, total_words):\n",
    "    values = [(word/total_words) * math.log(word/total_words) if word != 0 else 0 for word in word_occurences]\n",
    "    return sum(values)\n",
    "\n",
    "def H(word_occurences, total_words):\n",
    "    return shannon_entrophy(word_occurences, total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_contingency_table(bigram, bigram_count, total_words):\n",
    "    print(\"Calcualte contigency table called for\", bigram, bigram_count, total_words)\n",
    "    first, second = bigram[0], bigram[1]\n",
    "    first_occurence, second_occurence = sorted_rank[first], sorted_rank[second]\n",
    "    '''\n",
    "    |------  |---------| \n",
    "    | A,B    |B,notA   |\n",
    "    |------  |---------|\n",
    "    | A,notB |notA,notB|\n",
    "    |------|---------|\n",
    "    '''\n",
    "    return np.array[[bigram_count, first_occurence-bigram_count],\n",
    "            [second_occurence-bigram_count, total_words-first_occurence-second_occurence]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likeliheood_ratio(bigram):\n",
    "    print (\"log_likelihood_ratio called for \", bigram)\n",
    "    print (\"bigram\", bigram)\n",
    "    # TODO: FIX THAT\n",
    "#     print(\"bigram_result[bigram[0]]\", bigram_result[(bigram[0])])\n",
    "    print (bigram_result[('Nowy', 'Jork')])\n",
    "    k = calculate_contingency_table(bigram, bigram_result[bigram[0]], TOTAL_COUNT)\n",
    "\n",
    "    return 2 * np.sum(k) * (H(k) - H(k.sum(axis=0)) -H(k.sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood_ratio called for  (('Nowy', 'Jork'), 1)\n",
      "bigram (('Nowy', 'Jork'), 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sample() missing 1 required positional argument: 'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-0c7d9c6f8c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#     contingency_table = calculate_contingency_table()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtest_calculate_contingency_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-0c7d9c6f8c53>\u001b[0m in \u001b[0;36mtest_calculate_contingency_table\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbigram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigrams_frequency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         print (bigram)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_likeliheood_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#     contingency_table = calculate_contingency_table()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-fca7a1b71468>\u001b[0m in \u001b[0;36mlog_likeliheood_ratio\u001b[0;34m(bigram)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"log_likelihood_ratio called for \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"bigram\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(\"bigram_result[bigram[0]]\", bigram_result[(bigram[0])])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbigram_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nowy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Jork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sample() missing 1 required positional argument: 'k'"
     ]
    }
   ],
   "source": [
    "def test_calculate_contingency_table():\n",
    "    text = ['Nowy', 'Jork', 'to', 'piekne', 'miasto', 'Nowy', 'ale', 'nie', 'pies', 'Jork', 'stary', 'ani', 'Nowy']\n",
    "    bigram_of_text = nltk.bigrams(text)\n",
    "    bigrams_frequency = nltk.FreqDist(bigram_of_text)\n",
    "    for bigram in bigrams_frequency.items():\n",
    "#         print (bigram)\n",
    "        print (log_likeliheood_ratio(bigram))\n",
    "    #     contingency_table = calculate_contingency_table()\n",
    "\n",
    "test_calculate_contingency_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
